<!-- Generated by Ruler -->


<!-- Source: .ruler/AGENTS.md -->

# Extended Data Library - AI Agent Instructions

This is the central source of truth for AI agent instructions in this repository.
Rules defined here are distributed to all supported AI coding assistants via Ruler.

## Project Overview

This is a **uv workspace monorepo** (extended-data-library) containing multiple packages for data processing, logging, configuration, and vendor integrations.

### Packages

| Path | Package | Description |
|------|---------|-------------|
| `packages/extended-data-types` | extended-data-types | Python utility library (core) -- serialization, file system, data structures, strings, types |
| `packages/lifecyclelogging` | lifecyclelogging | Structured logging |
| `packages/directed-inputs-class` | directed-inputs-class | Input processing |
| `packages/vendor-connectors` | vendor-connectors | Vendor API connectors (AWS, Google, GitHub, Slack, etc.) |
| `packages/secretssync` | secretssync | Go CLI for secret syncing |
| `docs/` | -- | Astro/Starlight documentation site |

### Key Design Principles

- **Type safety**: Full type annotations and mypy compliance
- **Reliability**: Comprehensive test coverage with automated CI/CD
- **Ergonomics**: Clean, intuitive APIs
- **Platform awareness**: Handles cross-platform differences gracefully
- **Production ready**: No shortcuts, placeholders, or experimental features

## Technology Stack

- **Package manager**: `uv` (workspace mode, fast, Rust-based)
- **Build backend**: `hatchling`
- **Configuration**: `pyproject.toml` (root + per-package)
- **Python versions**: 3.10+
- **Go**: 1.25+ (secretssync only)
- **Docs**: Astro + Starlight
- **Linting & formatting**: `ruff`
- **Type checking**: `mypy` (strict mode)
- **Testing**: `pytest` (Python), `go test` (Go), `vitest` + `playwright` (docs)
- **CI/CD**: GitHub Actions
- **Releases**: `release-please` (NOT semantic-release)
- **PyPI publishing**: OIDC trusted publishers



<!-- Source: .ruler/00-fundamentals.md -->

# Fundamentals

## Before Acting

1. **Read before modifying** - Always read the file/code before editing
2. **Run builds after changes** - Verify your changes compile/lint
3. **Check git status** - Know what you're committing

## Making Changes

1. **One concern per commit** - Keep commits focused
2. **Run linters/tests locally** before pushing
3. **Don't consolidate code** without verifying the build

## When Copying/Moving Files

1. Read the file first
2. Check if content is relevant to destination
3. Update paths and references
4. Remove tool-specific cruft that doesn't apply

## Authentication

```bash
# jbcom repos - ALWAYS use this pattern
GH_TOKEN="$GITHUB_TOKEN" gh <command>
```

## Session Management

```bash
# Start of session
cat memory-bank/activeContext.md 2>/dev/null || echo "No memory bank"
gh issue list --label agent-session 2>/dev/null || true

# End of session - update context
echo "## Session: $(date +%Y-%m-%d)" >> memory-bank/activeContext.md
```



<!-- Source: .ruler/01-pr-workflow.md -->

# PR Workflow

## Creating PRs

1. **One feature/fix per PR** - Keep scope minimal
2. **Clear title**: `type(scope): description`
3. **Body explains** WHAT, WHY, and HOW

### Conventional Commit Types

| Type | Use Case |
|------|----------|
| `feat` | New feature - minor bump |
| `fix` | Bug fix - patch bump |
| `docs` | Documentation only |
| `chore` | Maintenance tasks |
| `refactor` | Code restructuring |
| `test` | Adding tests |

## AI Peer Review

**ALWAYS request AI reviews on PRs:**

```
/gemini review
/q review
@copilot review
```

## Addressing Feedback

1. Make commits that fix issues
2. Respond to EVERY comment (fix OR explain why not)
3. Re-request review after significant changes

### Resolving Review Threads

```bash
# Via GraphQL (preferred for batch resolution)
gh api graphql -f query='mutation {
  resolveReviewThread(input: {threadId: "PRRT_xxx"}) {
    thread { isResolved }
  }
}'
```

## Merging

- Wait for CI to pass
- Address all review comments
- Squash if commits are messy
- Never use `--admin` to bypass checks



<!-- Source: .ruler/02-memory-bank.md -->

# Memory Bank Protocol

## Purpose

Memory bank provides session continuity between agent runs. It's the "living memory" pattern.

## Files

| File | Purpose |
|------|---------|
| `memory-bank/activeContext.md` | Current state and focus |
| `memory-bank/progress.md` | Session-by-session log |

## Session Start

```bash
# Check context
if [ -f memory-bank/activeContext.md ]; then
  cat memory-bank/activeContext.md
fi

# Check for open issues
gh issue list --label agent-session 2>/dev/null || true
```

## Session End

```bash
# Update context
cat >> memory-bank/activeContext.md << 'EOF'

## Session: $(date +%Y-%m-%d)

### Completed
- [x] Task 1

### For Next Agent
- [ ] Follow-up task
EOF

# Commit if changes
git add memory-bank/
git commit -m "docs: update memory bank for handoff" || true
```

## Handoff Notes

When ending a session:

1. **Summarize completed work** - What got done
2. **List outstanding tasks** - What's left
3. **Document blockers** - What stopped progress
4. **Include references** - PRs, issues, file paths



<!-- Source: .ruler/03-ci-workflow.md -->

# CI/CD Workflow

## Branch Protection

- **main**: Protected, requires PR and CI pass
- **Feature branches**: `feat/`, `fix/`, `docs/`, `chore/`

## CI Checks

Every PR must pass:

1. **Build** - Package compiles/builds
2. **Test** - All tests pass
3. **Lint** - No linting errors
4. **Type check** - No type errors

## Watching CI

```bash
# List recent runs
gh run list --limit 5

# Watch a specific run
gh run watch <run-id>

# View run logs
gh run view <run-id> --log
```

## Fixing CI Failures

### Build Failures

```bash
# Python
uv sync && uv run pytest

# TypeScript
pnpm install && pnpm run build

# Go
go mod download && go build ./...
```

### Lint Failures

```bash
# Python
uvx ruff check --fix .
uvx ruff format .

# TypeScript
pnpm run lint:fix

# Go
golangci-lint run --fix
```

### Test Failures

1. Read the failure output carefully
2. Reproduce locally
3. Fix the code or the test
4. Verify fix locally before pushing

## Required Secrets

These secrets power CI/CD:

| Secret | Purpose |
|--------|---------|
| `CI_GITHUB_TOKEN` | GitHub API access |
| `PYPI_TOKEN` | PyPI publishing |
| `NPM_TOKEN` | npm publishing |
| `DOCKERHUB_USERNAME` | Docker Hub login |
| `DOCKERHUB_TOKEN` | Docker Hub publishing |

## Troubleshooting

### "Permission denied"

Token lacks required scopes. Check:
- `repo` scope for repository access
- `workflow` scope for Actions
- `write:packages` for package publishing

### "Rate limit exceeded"

Use authenticated requests:
```bash
GH_TOKEN="$GITHUB_JBCOM_TOKEN" gh api ...
```



<!-- Source: .ruler/04-releases.md -->

# Releases

## Versioning

All packages use **Semantic Versioning (SemVer)**: `MAJOR.MINOR.PATCH`

- **MAJOR**: Breaking changes
- **MINOR**: New features (backward compatible)
- **PATCH**: Bug fixes (backward compatible)

## Conventional Commits

Commits drive automatic version bumps via **release-please**:

```
feat(scope): new feature       - minor bump (x.Y.0)
fix(scope): bug fix            - patch bump (x.y.Z)
feat(scope)!: breaking change  - major bump (X.0.0)
```

### Package Scopes

| Scope | Package | Tag Prefix |
|-------|---------|------------|
| `edt` | extended-data-types | `edt-v` |
| `logging` | lifecyclelogging | `logging-v` |
| `inputs` | directed-inputs-class | `inputs-v` |
| `connectors` | vendor-connectors | `connectors-v` |
| `secretssync` | secretssync | `secretssync-v` |

## Release Process

```
Push to main with conventional commit
        |
CI runs tests & lint
        |
release-please analyzes commits
        |
Release PR created/updated (version bumps + changelogs)
        |
Release PR merged
        |
Tags created automatically
        |
Publish jobs triggered (PyPI / GoReleaser)
```

### Workflows

| Workflow | Trigger | Purpose |
|----------|---------|---------|
| `release.yml` | Push to main | release-please PR management + package publishing |
| `automerge.yml` | PR opened by bots | Auto-approve + squash-merge dependabot/release-please PRs |
| `cd.yml` | Push to main | Documentation deployment to GitHub Pages |

### Configuration Files

| File | Purpose |
|------|---------|
| `release-please-config.json` | Package definitions, release types, changelog config |
| `.release-please-manifest.json` | Current version tracking for each package |

## Dependabot

Dependabot creates grouped PRs (one per ecosystem) that are automatically merged by the automerge workflow. Merge commits include `[skip actions]` to prevent cascading workflow runs.

## What NOT to Do

- **Never** manually edit version numbers in `pyproject.toml` or the manifest
- **Never** create tags by hand (release-please manages tags)
- **Never** skip CI for releases
- **Never** merge release PRs with the "merge" strategy (always squash)

## Checking Release Status

```bash
# Check recent releases
gh release list --limit 5

# Check open release PRs
gh pr list --label "autorelease: pending"

# Check CI status
gh run list --limit 3

# View release-please manifest
cat .release-please-manifest.json
```



<!-- Source: .ruler/05-development.md -->

# Development Guidelines

## Core Philosophy

Write clean, tested, production-ready code. No shortcuts, no placeholders.

## Development Flow

1. **Read the requirements** from specs or issues
2. **Write tests first** (TDD approach)
3. **Implement the feature** completely
4. **Run linting**: `uvx ruff check packages/`
5. **Run tests**: `uv run pytest packages/<name>/tests/ -v`
6. **Commit** with conventional commits

## Testing Commands

```bash
# Install all workspace dependencies
uv sync

# Run tests for a specific package
uv run pytest packages/extended-data-types/tests/ -v
uv run pytest packages/lifecyclelogging/tests/ -v
uv run pytest packages/directed-inputs-class/tests/ -v
uv run pytest packages/vendor-connectors/tests/ -v

# Go tests
cd packages/secretssync && go test ./...

# Run with coverage for a specific package
uv run pytest packages/<name>/tests/ --cov=packages/<name>/src/ --cov-report=term-missing

# Linting
uvx ruff check packages/
uvx ruff format packages/

# Type checking for a specific package
uvx mypy packages/<name>/src/
```

## Commit Messages

Use conventional commits with package scopes matching release-please:
- `feat(scope): description` - minor bump
- `fix(scope): description` - patch bump
- `feat!: breaking change` - major bump

### Package Scopes

| Scope | Package |
|-------|---------|
| `edt` | extended-data-types |
| `logging` | lifecyclelogging |
| `inputs` | directed-inputs-class |
| `connectors` | vendor-connectors |
| `secretssync` | secretssync |

## Quality Standards

- All tests passing
- No linter errors
- Complete type annotations
- Proper error handling
- No TODOs or placeholders
- No shortcuts



<!-- Source: .ruler/languages/python.md -->

# Python Standards

## Style

- **Formatter**: Ruff (Black-compatible, 88 char line length)
- **Imports**: Sorted by ruff
- **Type hints**: Required on all public functions

```bash
# Format and lint
uvx ruff check --fix .
uvx ruff format .
```

## Naming

| Element | Convention | Example |
|---------|------------|---------|
| Functions/Variables | snake_case | `get_data()` |
| Classes | PascalCase | `DataProcessor` |
| Constants | UPPER_CASE | `MAX_RETRIES` |
| Private | Leading underscore | `_internal_helper()` |

## Type Hints

```python
# Modern style (Python 3.9+)
from collections.abc import Mapping, Sequence
from typing import Any

def process(items: list[dict[str, Any]]) -> dict[str, int]:
    return {"count": len(items)}

# Legacy style - avoid
from typing import Dict, List
def process(items: Dict[str, Any]) -> List[str]: ...
```

## Package Management

- **Tool**: uv (fast, Rust-based)
- **Config**: `pyproject.toml`
- **Lock file**: `uv.lock` (commit this)

```bash
# Install dependencies
uv sync

# Add dependency
uv add requests

# Add dev dependency
uv add --dev pytest
```

## Testing

- **Framework**: pytest
- **Location**: `tests/` directory
- **Run**: `pytest` or `tox -e <package>`

```bash
# Run tests
pytest

# With coverage
pytest --cov=src

# Specific test
pytest tests/test_utils.py::test_specific
```

## Imports

```python
# Use pathlib
from pathlib import Path
config = Path("config.yaml")

# Avoid os.path
import os
config = os.path.join("config.yaml")
```

## Docstrings

Use Google style:

```python
def process_items(items: list[dict], validate: bool = True) -> dict[str, Any]:
    """Process items and return summary.

    Args:
        items: List of item dictionaries.
        validate: Whether to validate before processing.

    Returns:
        Dictionary with processing results.

    Raises:
        ValueError: If items list is empty.
    """
```
